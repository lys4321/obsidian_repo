

시스템 간 데이터 수집을 위해 스트림 형태로 실시간으로 대응하여
그것을 통해 얻은 데이터를 관리하고 필요한 곳에 변별력 있게 공급하는 것?

시스템 구성
Producer(데이터 제공자) ->
Kafka Cluster(저장/관리, 요청에 대한 응답자) ->
Consumer(데이터 요청자)

실질적인 Apache Kafka 라는 것은 Kafka Cluster 이고 Producer와 Consumer는 API 로 Cluster를 사용하는 외부 프로그램

**Kafka Cluster**의 구성
	- Broker + Topic(Partitions)
	- 실제 구성 : Partitions(Leader Broker, Follower Broker, ...)

그리고 이 스트림을 안정적으로 유지하여 저장
또한 흐름 자체에 대하여 기록

서버 : 데이터 공급처와 연결(스트림)되어 가져오는 서버 클러스터, 일부는 브로커라는 스토리치 계층 구성, 그리고 가져온 데이터를 발산하는 스트림 있을 생성하여 클라이언트 카프카와 연결?, 에러 발생 시 다른 서버가 그 일을 이어받아 안정적 운영 가능

클라이언트 : 오류 발생 시 알아서 처리하는 클라이언트를 사용해 안정적 연결 유지, 지원하는 언어는 java, scala, go ,python, c/c++ 등을 지원하고 rest api 도 지원

카프카에선 이벤트 데이터란 무엇이 발생했다는 것에 대한 사실에 대한 데이터

프로듀서는 이 이벤트를 쓰고 전송하며 컨슈머는 이 이벤트를 받아 읽음
프로듀서는 컨슈머가 요청할 때 전송하는게 아닌 마음대로 전송하고 컨슈머는 그냥 그것을 받아 읽음

이벤트는 토픽이라는 일종의 파일시스템의 폴더와 유사한 공간에 영구적 저장(
기존 메세징 시스템과는 다른점이며 메세징 시스템에서는 삭제되었나?,
그리고 설정한 기간에 따라 자동 삭제 이뤄짐)

토픽은 프로듀서와 0..n:1관계이고 컨슈머와는1:0..n 관계이다(0..m:1:0..n 관계)
토픽은 분할이 가능하며 이 분할을 통해 브로커에 있는 버킷에 분산된다.
이를 통해 여러 브로커에 분산하여 데이터를 r/w 하므로 확장성에 중요
토픽에선 파티션이라는게 있으며 (이는 폴더 속 구분 폴더 비슷한?)토픽에서 이벤트가 게시되면 동일한 이벤트 키를 가진 이벤트는 토픽의 동일한 파티션에 저장하고
기록된 순서에 따라 동일하게 읽도록 보장한다.
토픽은 데이터의 내결함성과 고가용성을 확보하기 위해 위치한 리전이나 데이터 센터 간에도 복제 될 수 있다. 이는 문제 발생에 대한 대비이며 문제 발생 시 브로커 유지 관리를 위하여 여러 브로커에 데이터 사본이 저장된다. 이 복제는 토픽 파티션 수준에서 수행이 된다.

카프카 api 
admin api : 토픽, 브로커 및 기타 카프카 객체 관리/검사
프로듀서 api : n개에 대한 카프카 주제에 이벤트 스트림을 게시함
컨슈머 api : n개의 주제를 읽고 해당 주제에 대해 생성된 이벤트 스트림을 처리
카프카 스트림 api : 스트림을 처리하는 애플리케이션과 마이크로 서비스를 구현하며
변환, 집계, 조인 과 같은 상태 저장 작업, 윈도잉 이벤트, 이벤트 시간 기반 처리 등 이벤트 스트림을 처리하는 고급 기능을 제공한다. 여러 프로듀서와 여러 컨슈머 사이에서 입력 스트림에서 출력 스트림으로 변환
카프카 커넥트 api : 외부 시스템 및 애플리케이션과 이벤트 스트림을 생성(쓰기)/받으며(읽기)하는 재사용 데이터 커넥터를 구축/실행  하여 카프카와 통합되도록한다.


